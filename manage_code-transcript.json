{
  "chat_history": [
    {
      "role": "User",
      "content": "Clean up the changelogs display. We don't need to list the commit hash, and we don't need to say \"Assistant:\" before each line, just print them in a way that it's obvious that each item is a separate commit"
    },
    {
      "role": "Assistant",
      "content": "Got it! Let me know what changes you'd like to make, and I'll update the project accordingly."
    }
  ],
  "latest_code": "#!/usr/bin/env python3\nimport os\nimport re\nimport json\nimport argparse\nimport subprocess\nimport difflib\nfrom flask import Flask, request, render_template_string, send_from_directory, jsonify\nimport openai\n\n# Instantiate an OpenAI client with your API key.\nAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\nclient = openai.Client(api_key=API_KEY)\n\n# Global variables for the file we are managing, coding contexts, and debugging.\nSOURCE_FILE = None\nCODING_CONTEXTS = []\nDEBUG = False\n\n# HTML template for the chat interface.\nHTML_TEMPLATE = \"\"\"\n<!doctype html>\n<html>\n  <head>\n    <meta charset=\"utf-8\">\n    <title>Project Manager Chat</title>\n    <style>\n      body { font-family: sans-serif; margin: 20px; display: flex; flex-direction: column; }\n      #header { margin-bottom: 20px; }\n      #container { display: flex; gap: 20px; }\n      .section { border: 1px solid #ccc; padding: 10px; flex: 1; overflow-y: auto; height: 600px; }\n      #codeSection { }\n      #changelogSection { }\n      #conversationSection { }\n      textarea { width: 100%; height: 100%; resize: none; }\n      #throbber {\n        display: none;\n        width: 40px;\n        height: 40px;\n        border: 4px solid #ccc;\n        border-top: 4px solid #333;\n        border-radius: 50%;\n        animation: spin 1s linear infinite;\n        margin: 20px auto;\n      }\n      @keyframes spin {\n        0% { transform: rotate(0deg); }\n        100% { transform: rotate(360deg); }\n      }\n      .message { margin-bottom: 10px; }\n      .User { color: blue; }\n      .Assistant { color: green; }\n    </style>\n    <!-- Load Marked for Markdown parsing -->\n    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n    <script>\n      // Render Markdown while escaping any raw HTML.\n      function renderMarkdown(text) {\n        const renderer = new marked.Renderer();\n        renderer.html = function(html) {\n          return String(html).replace(/&/g, \"&amp;\").replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\");\n        };\n        return marked.parse(text, {\n          renderer: renderer,\n          headerIds: false,\n          mangle: false\n        });\n      }\n\n      document.addEventListener(\"DOMContentLoaded\", () => {\n        const chatForm = document.getElementById('chatForm');\n        const promptInput = document.getElementById('promptInput');\n        const throbber = document.getElementById('throbber');\n\n        const codeTextarea = document.getElementById('codeTextarea');\n        const changelogBox = document.getElementById('changelogBox');\n        const conversationBox = document.getElementById('conversationBox');\n\n        // Append a message to a given container; content is rendered as Markdown.\n        function appendMessage(container, role, content) {\n          const msgDiv = document.createElement('div');\n          msgDiv.className = 'message';\n          msgDiv.innerHTML = '<strong class=\"' + role + '\">' + role + ':</strong><div>' + renderMarkdown(content) + '</div>';\n          container.appendChild(msgDiv);\n        }\n\n        // Scroll a container to the bottom.\n        function scrollToBottom(container) {\n          container.scrollTop = container.scrollHeight;\n        }\n\n        // Load the existing conversation transcript from the server.\n        async function loadTranscript() {\n          try {\n            const response = await fetch('/transcript');\n            if (response.ok) {\n              const data = await response.json();\n              \n              // Populate code section\n              if (data.latest_code) {\n                codeTextarea.value = data.latest_code;\n              } else {\n                // Fallback to chat history if latest_code is not available\n                const latestCode = data.chat_history.find(msg => msg.role === \"Assistant\" && msg.code);\n                if (latestCode) {\n                  codeTextarea.value = latestCode.code;\n                }\n              }\n\n              // Populate changelog section\n              if (data.changelog) {\n                data.changelog.forEach(commit => {\n                  appendMessage(changelogBox, \"Assistant\", `${commit.commit_hash}: ${commit.commit_message}`);\n                });\n                scrollToBottom(changelogBox);\n              } else {\n                // Fallback to chat history if changelog is not available\n                data.chat_history.forEach(msg => {\n                  if (msg.role === \"Assistant\" && msg.commit_summary) {\n                    appendMessage(changelogBox, \"Assistant\", msg.commit_summary);\n                  }\n                });\n                scrollToBottom(changelogBox);\n              }\n\n              // Populate conversation section\n              data.chat_history.forEach(msg => {\n                if (msg.role === \"User\" || (msg.role === \"Assistant\" && msg.conversation)) {\n                  if (msg.role === \"Assistant\" && msg.conversation) {\n                    appendMessage(conversationBox, msg.role, msg.conversation);\n                  } else {\n                    appendMessage(conversationBox, msg.role, msg.content);\n                  }\n                }\n              });\n              scrollToBottom(conversationBox);\n            }\n          } catch (e) {\n            console.error('Error loading transcript:', e);\n          }\n        }\n\n        // Listen for Ctrl+Enter to submit the form.\n        promptInput.addEventListener(\"keydown\", function(e) {\n          if (e.ctrlKey && e.key === \"Enter\") {\n            e.preventDefault();\n            chatForm.dispatchEvent(new Event(\"submit\", {cancelable: true}));\n          }\n        });\n\n        chatForm.addEventListener('submit', async (e) => {\n          e.preventDefault();\n          const prompt = promptInput.value.trim();\n          if (!prompt) return;\n          appendMessage(conversationBox, \"User\", prompt);\n          scrollToBottom(conversationBox);\n          promptInput.value = \"\";\n          throbber.style.display = \"block\";\n\n          try {\n            const response = await fetch(\"/chat\", {\n              method: \"POST\",\n              headers: { \"Content-Type\": \"application/json\" },\n              body: JSON.stringify({ prompt: prompt })\n            });\n            if (response.ok) {\n              const data = await response.json();\n              // Update code section\n              const latest = data.chat_history[data.chat_history.length - 1];\n              if (latest.code) {\n                codeTextarea.value = latest.code;\n              }\n\n              // Update changelog section\n              if (latest.commit_summary) {\n                appendMessage(changelogBox, \"Assistant\", latest.commit_summary);\n                scrollToBottom(changelogBox);\n              }\n\n              // Update conversation section\n              if (latest.conversation) {\n                appendMessage(conversationBox, \"Assistant\", latest.conversation);\n                scrollToBottom(conversationBox);\n              }\n            } else {\n              console.error(\"Server error:\", response.statusText);\n            }\n          } catch (error) {\n            console.error(\"Fetch error:\", error);\n          }\n          throbber.style.display = \"none\";\n        });\n\n        // On startup, load the previous conversation (if any).\n        loadTranscript();\n      });\n    </script>\n  </head>\n  <body>\n    <div id=\"header\">\n      <h1>Project Manager Chat Interface</h1>\n      <p>Currently working on file: <strong>{{ source_file }}</strong></p>\n    </div>\n    <div id=\"container\">\n      <div id=\"codeSection\" class=\"section\">\n        <h2>Latest Code</h2>\n        <textarea id=\"codeTextarea\" readonly></textarea>\n      </div>\n      <div id=\"changelogSection\" class=\"section\">\n        <h2>Changelogs</h2>\n        <div id=\"changelogBox\"></div>\n      </div>\n      <div id=\"conversationSection\" class=\"section\">\n        <h2>Conversation</h2>\n        <div id=\"conversationBox\"></div>\n      </div>\n    </div>\n    <div id=\"throbber\"></div>\n    <hr>\n    <form id=\"chatForm\">\n      <textarea id=\"promptInput\" rows=\"5\" cols=\"60\" placeholder=\"Enter your prompt here...\"></textarea><br>\n      <input type=\"submit\" value=\"Submit\">\n    </form>\n  </body>\n</html>\n\"\"\"\n\n# In-memory conversation history.\nchat_history = []\n\ndef transcript_filename():\n    \"\"\"Return the transcript filename based on the active file's basename.\"\"\"\n    base, _ = os.path.splitext(SOURCE_FILE)\n    return f\"{base}-transcript.json\"\n\ndef load_transcript_from_disk():\n    \"\"\"Load transcript from disk into chat_history (if it exists).\"\"\"\n    fname = transcript_filename()\n    if os.path.exists(fname):\n        try:\n            with open(fname, \"r\") as f:\n                data = json.load(f)\n                if isinstance(data, dict):\n                    return data\n        except Exception:\n            pass\n    return {\"chat_history\": [], \"latest_code\": \"\", \"changelog\": []}\n\ndef update_transcript():\n    \"\"\"Write the current chat_history to the transcript file and commit it to git.\"\"\"\n    fname = transcript_filename()\n    transcript_data = {\n        \"chat_history\": chat_history,\n        \"latest_code\": read_source_file(),\n        \"changelog\": get_last_n_git_commits(20)\n    }\n    with open(fname, \"w\") as f:\n        json.dump(transcript_data, f, indent=2)\n    transcript_commit_msg = f\"Update transcript for {os.path.basename(SOURCE_FILE)}\"\n    commit_changes(fname, transcript_commit_msg)\n\ndef extract_commit_summary(text):\n    \"\"\"Search for a line starting with 'Commit Summary:' and return its content.\"\"\"\n    match = re.search(r\"Commit Summary:\\s*(.*)\", text)\n    return match.group(1).strip() if match else \"\"\n\ndef extract_code(text):\n    \"\"\"\n    Extract the contents of the first code block using a simple state machine.\n    The code block is assumed to start with a line that (after stripping whitespace)\n    starts with three backticks and ends when a line that is exactly three backticks is encountered.\n    \"\"\"\n    lines = text.splitlines()\n    in_code_block = False\n    code_lines = []\n    for line in lines:\n        stripped = line.strip()\n        if not in_code_block:\n            if stripped.startswith(\"```\"):\n                in_code_block = True\n            continue\n        else:\n            if stripped == \"```\":\n                break\n            code_lines.append(line)\n    return \"\\n\".join(code_lines).strip()\n\ndef extract_conversation(text):\n    \"\"\"Extract the conversational part after the code block and commit summary.\"\"\"\n    code_end = text.find(\"```\", text.find(\"```\") + 3)\n    if code_end == -1:\n        return \"\"\n    commit_start = text.find(\"Commit Summary:\", code_end)\n    if commit_start == -1:\n        return \"\"\n    conversation = text[commit_start + len(\"Commit Summary:\"):].strip()\n    return conversation\n\ndef compute_diff(old_content, new_content):\n    \"\"\"Compute a unified diff between old_content and new_content.\"\"\"\n    old_lines = old_content.splitlines(keepends=True)\n    new_lines = new_content.splitlines(keepends=True)\n    diff_lines = difflib.unified_diff(old_lines, new_lines, fromfile=\"Before\", tofile=\"After\")\n    return \"\".join(diff_lines)\n\ndef commit_changes(file_path, commit_message):\n    \"\"\"Stage the given file and commit changes to git with the provided commit message.\"\"\"\n    try:\n        subprocess.run([\"git\", \"add\", file_path], check=True)\n        subprocess.run([\"git\", \"commit\", \"-m\", commit_message], check=True)\n        return True\n    except subprocess.CalledProcessError:\n        return False\n\ndef load_coding_contexts(context_names):\n    \"\"\"Load coding contexts from the contexts/ directory based on provided context names.\"\"\"\n    contexts = []\n    for name in context_names:\n        context_path = os.path.join(\"contexts\", f\"{name}.txt\")\n        if os.path.exists(context_path):\n            try:\n                with open(context_path, \"r\") as f:\n                    content = f.read().strip()\n                    if content:\n                        contexts.append(content)\n            except Exception as e:\n                print(f\"Error loading context '{name}': {e}\")\n        else:\n            print(f\"Context file '{context_path}' does not exist.\")\n    return contexts\n\ndef build_prompt_messages(system_prompt, transcript, source_file, model, coding_contexts):\n    \"\"\"\n    Build a list of messages for the API:\n      - Include the coding contexts at the beginning of the system prompt.\n      - Include the system prompt. If the model is \"o1-mini\" (which doesn't support 'system'),\n        include it as a user message prefixed with \"SYSTEM:\".\n      - For each user message, include it verbatim.\n      - For each assistant message, include only the commit summary and conversation.\n      - Append a final user message with the current on-disk file contents.\n    \"\"\"\n    messages = []\n    if coding_contexts:\n        combined_context = \"\\n\".join([f\"Context: {ctx}\" for ctx in coding_contexts])\n        system_prompt = f\"{combined_context}\\n\\n{system_prompt}\"\n    if model == \"o1-mini\":\n        messages.append({\"role\": \"user\", \"content\": \"SYSTEM: \" + system_prompt})\n    else:\n        messages.append({\"role\": \"system\", \"content\": system_prompt})\n    for msg in transcript[\"chat_history\"]:\n        role = msg[\"role\"].lower()\n        if role == \"assistant\":\n            commit = extract_commit_summary(msg[\"content\"])\n            convo = extract_conversation(msg[\"content\"])\n            if commit:\n                messages.append({\"role\": \"assistant\", \"content\": commit})\n            if convo:\n                messages.append({\"role\": \"assistant\", \"content\": convo})\n        else:\n            messages.append({\"role\": \"user\", \"content\": msg[\"content\"]})\n    final_msg = {\n        \"role\": \"user\",\n        \"content\": \"The following is the code which has been generated so far:\\n\" + transcript[\"latest_code\"]\n    }\n    messages.append(final_msg)\n    return messages\n\ndef read_source_file():\n    \"\"\"Read and return the content of the source file.\"\"\"\n    try:\n        with open(SOURCE_FILE, \"r\") as f:\n            return f.read()\n    except Exception:\n        return \"\"\n\ndef get_last_n_git_commits(n=20):\n    \"\"\"Retrieve the last n git commits.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"git\", \"log\", f\"-n{n}\", \"--pretty=format:%H|%s\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True\n        )\n        commits = []\n        for line in result.stdout.strip().split('\\n'):\n            if '|' in line:\n                commit_hash, commit_message = line.split('|', 1)\n                commits.append({\"commit_hash\": commit_hash, \"commit_message\": commit_message})\n        return commits\n    except subprocess.CalledProcessError as e:\n        print(f\"Error retrieving git commits: {e.stderr}\")\n        return []\n\napp = Flask(__name__)\n\n# Route to serve static files from the static/ directory.\n@app.route(\"/static/<path:filename>\")\ndef serve_static(filename):\n    return send_from_directory(\"static\", filename)\n\n# Route to return the current transcript as JSON.\n@app.route(\"/transcript\", methods=[\"GET\"])\ndef get_transcript():\n    transcript = {\n        \"chat_history\": chat_history,\n        \"latest_code\": read_source_file(),\n        \"changelog\": get_last_n_git_commits(20)\n    }\n    return jsonify(transcript)\n\n# Chat endpoint: accepts a JSON prompt, updates conversation, file, and transcript, then returns the full conversation.\n@app.route(\"/chat\", methods=[\"POST\"])\ndef chat():\n    global chat_history, SOURCE_FILE, DEBUG\n    data = request.get_json()\n    if not data or \"prompt\" not in data:\n        return jsonify({\"error\": \"No prompt provided.\"}), 400\n    user_input = data[\"prompt\"]\n    chat_history.append({\"role\": \"User\", \"content\": user_input})\n\n    if not os.path.exists(SOURCE_FILE) or os.path.getsize(SOURCE_FILE) == 0:\n        system_prompt = (\n            \"You are an assistant managing a software project. When given a prompt, generate the complete contents \"\n            \"for the project file. Output only the code in a single code block (using triple backticks) without commentary.\"\n        )\n    else:\n        system_prompt = (\n            \"You are an assistant managing a software project. The project file already has content. When given a prompt for changes, \"\n            \"generate the complete updated file contents. Output only the updated code in a single code block (using triple backticks). \"\n            \"Then, on a new line after the code block, output a commit summary starting with 'Commit Summary:' followed by a brief description of the changes. \"\n            \"Additionally, provide a conversational response as if you're a coworker discussing the changes.\"\n        )\n\n    transcript = load_transcript_from_disk()\n    messages = build_prompt_messages(system_prompt, transcript, SOURCE_FILE, \"o1-mini\", CODING_CONTEXTS)\n\n    if DEBUG:\n        print(\"DEBUG: AI prompt messages:\")\n        print(json.dumps(messages, indent=2))\n\n    try:\n        response = client.chat.completions.create(\n            model=\"o1-mini\",\n            messages=messages,\n            temperature=1\n        )\n    except Exception as e:\n        error_msg = f\"Error calling OpenAI API: {str(e)}\"\n        chat_history.append({\"role\": \"Assistant\", \"content\": error_msg})\n        update_transcript()\n        return jsonify({\"chat_history\": chat_history}), 500\n\n    reply = response.choices[0].message.content\n    # Parse the reply into code, commit summary, and conversation\n    new_file_content = extract_code(reply)\n    commit_summary = extract_commit_summary(reply)\n    conversation = extract_conversation(reply)\n\n    if new_file_content:\n        chat_history.append({\"role\": \"Assistant\", \"content\": reply, \"code\": new_file_content, \"commit_summary\": commit_summary, \"conversation\": conversation})\n    else:\n        chat_history.append({\"role\": \"Assistant\", \"content\": reply})\n\n    if new_file_content:\n        if not os.path.exists(SOURCE_FILE) or os.path.getsize(SOURCE_FILE) == 0:\n            with open(SOURCE_FILE, \"w\") as f:\n                f.write(new_file_content)\n        else:\n            old_content = read_source_file()\n            diff_text = compute_diff(old_content, new_file_content)\n            if diff_text:\n                with open(SOURCE_FILE, \"w\") as f:\n                    f.write(new_file_content)\n                commit_msg = commit_summary if commit_summary else f\"Applied changes: {user_input}\"\n                if not commit_changes(SOURCE_FILE, commit_msg):\n                    chat_history.append({\"role\": \"Assistant\", \"content\": \"Error committing changes to git.\"})\n            else:\n                chat_history.append({\"role\": \"Assistant\", \"content\": \"No changes detected.\"})\n\n    update_transcript()\n    return jsonify({\n        \"chat_history\": chat_history,\n        \"latest_code\": read_source_file(),\n        \"changelog\": get_last_n_git_commits(20)\n    })\n\n# Main page: serves the HTML page with the active file indicator.\n@app.route(\"/\", methods=[\"GET\"])\ndef index():\n    return render_template_string(HTML_TEMPLATE, source_file=SOURCE_FILE)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Manage a software project via the OpenAI API.\")\n    parser.add_argument(\"source_file\", help=\"Path to the project file to manage.\")\n    parser.add_argument(\"--port\", type=int, default=5000, help=\"Port on which the server will run (default: 5000)\")\n    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Print full AI prompt on each API call for debugging.\")\n    parser.add_argument(\"--contexts\", nargs='*', default=[], help=\"List of coding contexts to apply.\")\n    args = parser.parse_args()\n\n    SOURCE_FILE = args.source_file\n    DEBUG = args.debug\n    if not os.path.exists(SOURCE_FILE):\n        open(SOURCE_FILE, \"w\").close()\n    transcript = load_transcript_from_disk()\n    CODING_CONTEXTS = load_coding_contexts(args.contexts)\n\n    app.run(port=args.port)",
  "changelog": [
    {
      "commit_hash": "b6d17345f8e2f0ff89be91c0dcabfa5069c84d5b",
      "commit_message": "Update transcript for manage_code.py"
    },
    {
      "commit_hash": "0d3f7783ec3a0936cfee25fe5092dadda98740bf",
      "commit_message": "' and return its content.\"\"\""
    },
    {
      "commit_hash": "ef1348d769c2696541eccb6edc9be0125f29cfad",
      "commit_message": "Update transcript for manage_code.py"
    },
    {
      "commit_hash": "833429a337a9bc61ee09f70e19d3a77f2bb0f131",
      "commit_message": "' and return its content.\"\"\""
    },
    {
      "commit_hash": "5edad85013f962be56e037dee26401deacd260ee",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "e7b7b92fab9dd94a062e971cdd1c9a76efca01c0",
      "commit_message": "Decreased `spinDuration` to 0.2 seconds and `spinAngle` to 180 degrees for clickable cubes' spin animation."
    },
    {
      "commit_hash": "0e5f776e3d67b7c8e23726c79e411c258a92435b",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "b7d509200688180b6860d26f817f8e9b2a8810cd",
      "commit_message": "Increased spinDuration to 1 second."
    },
    {
      "commit_hash": "e398c86b499ce9c7a967b1e59c193e48b3d3cf01",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "36ef9f59bc20827333c4d97e5ba7355623afc60a",
      "commit_message": "Changed cube rotations from radians to degrees by updating spin angles to use 360 degrees and adjusted rotation tweening accordingly."
    },
    {
      "commit_hash": "903718ab6e93d1482735c65c3267e978aa6318d2",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "435792c9e7285444e7fe9b2a0e68e89b6cdbecc3",
      "commit_message": "Removed the `this.rotation = V(this.rotation);` line from the `update` function in the `clickable-cube` custom element to stop overriding the engine's rotation detection."
    },
    {
      "commit_hash": "085adda6df1592a4aef303151b89d7b31ffaa263",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "b53e6bafd01f93bcdf2c66aba14111882b32ac16",
      "commit_message": "Added `update` function to `<clickable-cube>` elements to ensure rotation changes are detected by the engine."
    },
    {
      "commit_hash": "817f73a7ac6c2c785094e8d6c262613dbe724267",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "ac1d32123a6195c1c9acce3ec751b7a3e758e26a",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "38f81b610bb654e33e72e0370d63b561a856f728",
      "commit_message": "Updated `<clickable-cube>` elements to spawn cube objects with `id=\"cube\"` and `collision_id=\"cube\"`, ensuring visibility and proper collision handling."
    },
    {
      "commit_hash": "4c42d75203018c46142570388a2ceea3924daf6c",
      "commit_message": "Update transcript for janus-context-test.html"
    },
    {
      "commit_hash": "5a726661fab6dc07f60a6dfd6bde807f8ea211ee",
      "commit_message": "Updated `<clickable-cube>` custom elements to spawn visible cube objects with unique `collision_id`s and adjusted event listeners to trigger jump and spin animations on the spawned cubes."
    },
    {
      "commit_hash": "b70bafd8e29adff07add189a9aeef117cbb3ebbc",
      "commit_message": "Update transcript for janus-context-test.html"
    }
  ]
}